I"<<h1 id="模型校准的含义">模型校准的含义</h1>

<p>模型校准的含义是将模型最终的输出转化为概率。[1]中介绍了通常SVM、BST等算法需要校准，而神经网络、bagged tree、random forest、逻辑回归等算法会好一些，常用的评价指标是reliability diagram，如下图所示，reliability diagram越靠近对角线则说明模型校准效果越好，反之则校准效果较差。常用的校准算法有Platt Calibration 和 Isotonic Regression等。</p>

<p><img src="/img/in-post/post-paper-notes-model calibration/reliability diagram.jpg" alt="" /></p>

<p>但其实神经网络输出的概率也是需要校准的，因为某些任务场景下模型输出概率能否代表真实概率很重要，这样对于概率较低的样本可以设置阈值进行人工判断，</p>

<p>本文是将原型思想应用于模型概率校准的一篇文章。通常我们将网络最后层softmax的值看做属于各个类别的概率，但其实这是欠妥的，网络往往会对它没有把握的样本也给予较高概率的预测，因此需要进行概率的校准。</p>

<p><img src="/img/in-post/post-paper-notes-ProtoAttend and DBLE/DBLE.jpg" alt="" /></p>

<p>如上图，本文与原型网络很相似，不同点在于原型网络中样本与各个类别的距离经过softmax后即为属于该类别的概率，而在DBLE中，该概率需要校准。</p>

<p>训练时过程中，如果该样本分类错误，其概率才需要校准。假设它服从各向同性的高斯分布，以该样本为均值，那么其方差 $\sigma$ 就应该较大，这样重新sample出的样本才能尽可能地接近真实类别。</p>

<p>而测试时因为不知道真实标签，所以所有样本的概率都需要校准。具体操作是利用训练好的 $\sigma$ 进行sample，取多次sample出的样本预测均值作为最终的预测概率。</p>

<p><img src="/img/in-post/post-paper-notes-ProtoAttend and DBLE/calibration.jpg" alt="" /></p>

<p>概率校准的评价标准并不是简单的acc，本文还使用了 Expected Calibration Error(ECE) 和 Negative Log Likelihood(NLL)，结果表明DBLE效果最好。</p>

<p><img src="/img/in-post/post-paper-notes-ProtoAttend and DBLE/result.jpg" alt="" /></p>

<p>一些思考</p>

<p>1、本文的训练策略使用了小样本的episode策略，实验说明episode效果更好。</p>

<p>2、训练时概率校准仅适用分类错误的样本，这算是一种困难样本挖掘技术，作者在消融实验部分证明了其有效性。</p>

<p><img src="/img/in-post/post-paper-notes-ProtoAttend and DBLE/ablation.jpg" alt="" /></p>

<p>3、作者假设服从的是各向同性的高斯分布，那么真实情况下可能是各向异性的，猜测各项异性需要预测的参数过多，使得模型难训练，因此引入各向同性的先验。</p>
:ET