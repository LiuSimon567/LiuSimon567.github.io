I"t	<h1 id="a-baseline-for-few-shot-image-classification">A BASELINE FOR FEW-SHOT IMAGE CLASSIFICATION</h1>
<p>本文提出一个很强的baseline，首先在大规模数据上预训练得到pretrainNet，接着在测试阶段进行finetune，finetune的具体步骤：</p>

<p>1、SUPPORT-BASED INITIALIZATION</p>

<p>在预训练网络的最后的FC分类层后再加上一层分类器，新分类器的输出为此时的类别数，注意是直接加上，而不是去掉最后的FC分类层，在之前的特征层之后加上，这么做的原因是Analyzing and improving representations with the soft nearest neighbor loss中指出网络的最后一层纠缠度较低，具有最好的聚类效果，而特征层的数据纠缠度较高，因此在最后的FC分类层后加分类器，更适用于小样本学习。</p>

<p>而此时新分类器包含参数W和b，w的初始值为各类别之前FC层输出值归一化后的平均值，b的初始值为0，这样可以使得属于该类中的数据激活值最高。
<img src="/img/in-post/post-paper-notes-A BASELINE FOR FEW-SHOT IMAGE CLASSIFICATION/w_b.jpg" alt="w_b" /></p>

<p>2、TRANSDUCTIVE FINE-TUNING</p>

<p>虽说本文认为这是一种转导的微调方法，但我认为只是添加了基于最小熵约束的微调而已，各个query的预测仍然是相对独立的，没有利用到相互之间的信息。</p>

<p><img src="/img/in-post/post-paper-notes-A BASELINE FOR FEW-SHOT IMAGE CLASSIFICATION/loss.jpg" alt="loss" /></p>

<p>（META-LEARNING FOR SEMI-SUPERVISED FEW-SHOT CLASSIFICATION中说到转导和半监督其实有联系，如果把转导的那些数据不放到queryset中，那么也就是半监督的方法）</p>

<p>3、本文提出一种新的评价指标，类似AOU，通过计算way数逐渐增多情况下方法准确率曲线下的面积，来衡量方法的好坏。</p>

<p>4、我认为类似baseline的传统训练策略效果好的主要原因是可以在test阶段根据supportset中数据进行finetune，而基于metric的很多方法，例如protoNet、RelationNet不具备这种功能，基于MAML的方法倒是也有这种finetune的过程。</p>

<p><img src="/img/in-post/post-paper-notes-A BASELINE FOR FEW-SHOT IMAGE CLASSIFICATION/framework.jpg" alt="loss" />
<img src="/img/in-post/CROSS-DOMAIN FEW-SHOT CLASSIFICATION VIA LEARNED FEATURE-WISE TRANSFORMATION/framework.jpg" alt="算法原理图" /></p>
:ET